[20141103 16:26:53-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:26:53-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:26:53-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:26:53-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:26:53-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:26:53-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:26:53-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003213868 and write data
[20141103 16:26:53-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:26:54-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:26:54-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:26:54-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:26:54-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:26:54-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:26:54-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:26:54-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003214675 and write data
[20141103 16:26:54-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:26:56-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:26:56-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:26:56-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:26:56-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:26:56-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:26:56-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:26:56-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003216031 and write data
[20141103 16:26:56-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:26:57-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:26:57-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:26:57-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:26:57-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:26:57-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:26:57-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:26:57-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003217291 and write data
[20141103 16:26:57-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:26:59-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:26:59-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:26:59-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:26:59-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:26:59-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:26:59-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:26:59-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003219038 and write data
[20141103 16:26:59-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:02-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:02-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:02-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:02-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:02-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:02-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:02-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003222254 and write data
[20141103 16:27:02-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:03-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:03-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:03-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:03-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:03-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:03-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:03-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003223684 and write data
[20141103 16:27:03-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:05-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:05-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:05-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:05-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:05-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:05-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:05-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003225139 and write data
[20141103 16:27:05-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:06-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:06-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:06-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:06-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:06-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:06-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:06-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003226914 and write data
[20141103 16:27:07-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:08-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:08-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:08-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:08-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:08-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:08-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:08-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003228089 and write data
[20141103 16:27:08-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:09-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:09-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:09-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:09-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:09-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:09-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:09-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003229546 and write data
[20141103 16:27:09-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:10-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:10-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:10-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:10-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:10-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:10-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:10-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003230668 and write data
[20141103 16:27:10-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:11-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:11-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:11-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:11-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:11-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:11-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:11-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003231480 and write data
[20141103 16:27:11-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:12-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:12-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:12-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:12-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:12-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:12-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:12-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003232352 and write data
[20141103 16:27:12-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:13-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:13-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:13-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:13-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:13-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:13-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:13-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003233169 and write data
[20141103 16:27:13-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:14-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:14-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:14-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:14-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:14-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:14-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:14-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003234711 and write data
[20141103 16:27:14-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:17-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:17-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:17-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:17-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:17-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:17-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:17-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003237016 and write data
[20141103 16:27:17-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:18-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:18-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:18-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:18-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:18-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:18-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:18-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003238131 and write data
[20141103 16:27:18-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:19-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:19-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:19-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:19-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:19-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:19-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:19-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003239335 and write data
[20141103 16:27:19-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:20-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:20-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:20-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:20-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:20-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:20-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:20-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003240139 and write data
[20141103 16:27:20-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:20-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:20-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:20-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:20-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:21-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:21-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:21-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003240976 and write data
[20141103 16:27:21-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:21-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:21-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:21-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:21-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:21-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:21-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:21-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003241784 and write data
[20141103 16:27:21-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:22-INFO][ZooKeeper.java:438][RMI TCP Connection(8)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x356b6707, quorum=master:2181, baseZNode=/hbase
[20141103 16:27:22-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(8)-192.168.10.108]-- Process identifier=hconnection-0x356b6707 connecting to ZooKeeper ensemble=master:2181
[20141103 16:27:22-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:27:22-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:27:22-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0065, negotiated timeout = 90000
[20141103 16:27:22-INFO][HConnectionManager.java:1798][RMI TCP Connection(8)-192.168.10.108]-- Closing zookeeper sessionid=0x14974a850ae0065
[20141103 16:27:22-INFO][ZooKeeper.java:684][RMI TCP Connection(8)-192.168.10.108]-- Session: 0x14974a850ae0065 closed
[20141103 16:27:22-INFO][ClientCnxn.java:509][RMI TCP Connection(8)-192.168.10.108-EventThread]-- EventThread shut down
[20141103 16:27:22-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:22-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:22-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:22-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:22-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:22-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:23-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003242919 and write data
[20141103 16:27:23-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:24-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:24-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:24-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:24-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:24-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:24-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:24-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003244284 and write data
[20141103 16:27:24-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:25-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:25-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:25-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:25-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:25-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:25-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:25-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003245885 and write data
[20141103 16:27:25-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:26-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:26-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:26-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:26-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:26-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:26-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:26-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003246779 and write data
[20141103 16:27:26-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:28-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:28-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:28-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:28-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:28-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:28-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:28-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003248047 and write data
[20141103 16:27:28-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:29-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:29-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:29-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:29-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:29-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:29-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:29-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003249676 and write data
[20141103 16:27:29-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:30-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:30-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:30-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:30-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:30-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:30-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:30-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003250590 and write data
[20141103 16:27:30-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:31-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:31-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:31-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:31-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:31-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:31-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:31-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003251446 and write data
[20141103 16:27:31-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:32-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:32-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:32-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:32-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:32-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:32-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:32-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003252289 and write data
[20141103 16:27:32-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:33-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:33-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:33-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:33-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:33-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:33-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:33-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003253153 and write data
[20141103 16:27:33-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:34-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:27:34-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:27:34-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:27:34-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:27:34-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:27:34-ERROR][HadoopFileUtil.java:113][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInternal(FSNamesystem.java:3793)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirsInt(FSNamesystem.java:3763)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3737)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:778)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:573)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:27:34-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415003254020 and write data
[20141103 16:27:34-ERROR][HadoopFileUtil.java:47][pool-4-thread-1]-- Permission denied: user=Administrator, access=WRITE, inode="/":hadoop:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkFsPermission(FSPermissionChecker.java:271)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:257)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:238)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:179)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5904)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkPermission(FSNamesystem.java:5886)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkAncestorAccess(FSNamesystem.java:5860)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:2362)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2315)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2266)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:542)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:369)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1614)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

[20141103 16:39:02-WARN][NativeCodeLoader.java:62][RMI TCP Connection(7)-192.168.10.108]-- Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:host.name=USER-20140101YF
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:java.version=1.7.0_45
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:java.vendor=Oracle Corporation
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:java.home=C:\Program Files\Java\jre7
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:java.class.path=E:\dataresouce\SCP\scp\scp_data_adapter\target\classes;C:\Users\Administrator\.m2\repository\org\springframework\spring-context\3.2.3.RELEASE\spring-context-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-aop\3.2.3.RELEASE\spring-aop-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-beans\3.2.3.RELEASE\spring-beans-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-core\3.2.3.RELEASE\spring-core-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-expression\3.2.3.RELEASE\spring-expression-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-client\2.5.0\hadoop-client-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-common\2.5.0\hadoop-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\Administrator\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\Administrator\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\Administrator\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\Administrator\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\Administrator\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\Administrator\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.5.0\hadoop-mapreduce-client-app-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.5.0\hadoop-mapreduce-client-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.5.0\hadoop-yarn-client-2.5.0.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.5.0\hadoop-yarn-server-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.5.0\hadoop-mapreduce-client-shuffle-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.0\hadoop-yarn-api-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.0\hadoop-mapreduce-client-core-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.0\hadoop-yarn-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\Administrator\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\Administrator\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.5.0\hadoop-mapreduce-client-jobclient-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.0\hadoop-annotations-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.5.0\hadoop-hdfs-2.5.0.jar;C:\Users\Administrator\.m2\repository\com\google\guava\guava\11.0.2\guava-11.0.2.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\Administrator\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\Administrator\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\Administrator\.m2\repository\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;C:\Users\Administrator\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\Administrator\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\Administrator\.m2\repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;C:\Users\Administrator\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\Administrator\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\Administrator\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\Administrator\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\Administrator\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\Administrator\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\Administrator\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\Administrator\.m2\repository\org\springframework\data\spring-data-hadoop\1.0.1.RELEASE\spring-data-hadoop-1.0.1.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-context-support\3.0.7.RELEASE\spring-context-support-3.0.7.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-streaming\1.2.1\hadoop-streaming-1.2.1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-tools\1.2.1\hadoop-tools-1.2.1.jar;C:\Users\Administrator\.m2\repository\dom4j\dom4j\1.6.1\dom4j-1.6.1.jar;C:\Users\Administrator\.m2\repository\xml-apis\xml-apis\1.0.b2\xml-apis-1.0.b2.jar;C:\Users\Administrator\.m2\repository\org\quartz-scheduler\quartz\2.2.1\quartz-2.2.1.jar;C:\Users\Administrator\.m2\repository\c3p0\c3p0\0.9.1.1\c3p0-0.9.1.1.jar;C:\Users\Administrator\.m2\repository\org\quartz-scheduler\quartz-jobs\2.2.1\quartz-jobs-2.2.1.jar;C:\Users\Administrator\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-api\1.7.5\slf4j-api-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\jcl-over-slf4j\1.7.5\jcl-over-slf4j-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-log4j12\1.7.5\slf4j-log4j12-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-nop\1.7.5\slf4j-nop-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-client\0.96.2-hadoop2\hbase-client-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-common\0.96.2-hadoop2\hbase-common-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-protocol\0.96.2-hadoop2\hbase-protocol-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\zookeeper\zookeeper\3.4.5\zookeeper-3.4.5.jar;C:\Users\Administrator\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\Administrator\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-core\1.2.1\hadoop-core-1.2.1.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-json\1.8\jersey-json-1.8.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\Administrator\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\Administrator\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.7.1\jackson-jaxrs-1.7.1.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-xc\1.7.1\jackson-xc-1.7.1.jar;C:\Users\Administrator\.m2\repository\commons-httpclient\commons-httpclient\3.0.1\commons-httpclient-3.0.1.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\Administrator\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\Administrator\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\Administrator\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\Administrator\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\Administrator\.m2\repository\commons-net\commons-net\1.4.1\commons-net-1.4.1.jar;C:\Users\Administrator\.m2\repository\tomcat\jasper-compiler\5.5.12\jasper-compiler-5.5.12.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\Administrator\.m2\repository\ant\ant\1.6.5\ant-1.6.5.jar;C:\Users\Administrator\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\Administrator\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\Administrator\.m2\repository\hsqldb\hsqldb\1.8.0.10\hsqldb-1.8.0.10.jar;C:\Users\Administrator\.m2\repository\oro\oro\2.0.8\oro-2.0.8.jar;C:\Users\Administrator\.m2\repository\org\eclipse\jdt\core\3.1.1\core-3.1.1.jar
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:java.library.path=C:\Program Files\Java\jre7\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;%CATALINA_HOME%\bin;\System32\WindowsPowerShell\v1.0\ \C:\Program Files\TortoiseGit\bin;D:\apache-maven-3.0.5\bin;%HADOOP_HOME%\bin;;.
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:java.compiler=<NA>
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:os.name=Windows 7
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:os.arch=amd64
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:os.version=6.1
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:user.name=Administrator
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:user.home=C:\Users\Administrator
[20141103 16:39:02-INFO][Environment.java:100][RMI TCP Connection(7)-192.168.10.108]-- Client environment:user.dir=E:\dataresouce\SCP\scp\scp_data_adapter
[20141103 16:39:02-INFO][ZooKeeper.java:438][RMI TCP Connection(7)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x5e7ef926, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:02-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(7)-192.168.10.108]-- Process identifier=hconnection-0x5e7ef926 connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:02-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:02-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:02-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae007a, negotiated timeout = 90000
[20141103 16:39:03-INFO][HConnectionManager.java:1798][RMI TCP Connection(7)-192.168.10.108]-- Closing zookeeper sessionid=0x14974a850ae007a
[20141103 16:39:03-INFO][ZooKeeper.java:684][RMI TCP Connection(7)-192.168.10.108]-- Session: 0x14974a850ae007a closed
[20141103 16:39:03-INFO][ClientCnxn.java:509][RMI TCP Connection(7)-192.168.10.108-EventThread]-- EventThread shut down
[20141103 16:39:04-INFO][StdSchedulerFactory.java:1184][RMI TCP Connection(7)-192.168.10.108]-- Using default implementation for ThreadExecutor
[20141103 16:39:04-INFO][SimpleThreadPool.java:268][RMI TCP Connection(7)-192.168.10.108]-- Job execution threads will use class loader of thread: RMI TCP Connection(7)-192.168.10.108
[20141103 16:39:04-INFO][SchedulerSignalerImpl.java:61][RMI TCP Connection(7)-192.168.10.108]-- Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
[20141103 16:39:04-INFO][QuartzScheduler.java:240][RMI TCP Connection(7)-192.168.10.108]-- Quartz Scheduler v.2.2.1 created.
[20141103 16:39:04-INFO][RAMJobStore.java:155][RMI TCP Connection(7)-192.168.10.108]-- RAMJobStore initialized.
[20141103 16:39:04-INFO][QuartzScheduler.java:305][RMI TCP Connection(7)-192.168.10.108]-- Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

[20141103 16:39:04-INFO][StdSchedulerFactory.java:1339][RMI TCP Connection(7)-192.168.10.108]-- Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
[20141103 16:39:04-INFO][StdSchedulerFactory.java:1343][RMI TCP Connection(7)-192.168.10.108]-- Quartz scheduler version: 2.2.1
[20141103 16:39:04-INFO][QuartzScheduler.java:575][RMI TCP Connection(7)-192.168.10.108]-- Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
[20141103 16:39:04-INFO][ZooKeeper.java:438][RMI TCP Connection(7)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x53cf39d5, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:04-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(7)-192.168.10.108]-- Process identifier=hconnection-0x53cf39d5 connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:04-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:04-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:04-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae007c, negotiated timeout = 90000
[20141103 16:39:04-INFO][ZooKeeper.java:438][RMI TCP Connection(7)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x5141185c, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:04-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(7)-192.168.10.108]-- Process identifier=hconnection-0x5141185c connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:04-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:04-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:04-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae007d, negotiated timeout = 90000
[20141103 16:39:04-INFO][HConnectionManager.java:1798][RMI TCP Connection(7)-192.168.10.108]-- Closing zookeeper sessionid=0x14974a850ae007d
[20141103 16:39:04-INFO][ZooKeeper.java:684][RMI TCP Connection(7)-192.168.10.108]-- Session: 0x14974a850ae007d closed
[20141103 16:39:04-INFO][ClientCnxn.java:509][RMI TCP Connection(7)-192.168.10.108-EventThread]-- EventThread shut down
[20141103 16:39:05-INFO][ZooKeeper.java:438][RMI TCP Connection(7)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x1958f2e1, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:05-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(7)-192.168.10.108]-- Process identifier=hconnection-0x1958f2e1 connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:05-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:05-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:05-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae007e, negotiated timeout = 90000
[20141103 16:39:05-INFO][HConnectionManager.java:1798][RMI TCP Connection(7)-192.168.10.108]-- Closing zookeeper sessionid=0x14974a850ae007e
[20141103 16:39:05-INFO][ZooKeeper.java:684][RMI TCP Connection(7)-192.168.10.108]-- Session: 0x14974a850ae007e closed
[20141103 16:39:05-INFO][ClientCnxn.java:509][RMI TCP Connection(7)-192.168.10.108-EventThread]-- EventThread shut down
[20141103 16:39:05-INFO][HConnectionManager.java:1798][RMI TCP Connection(7)-192.168.10.108]-- Closing zookeeper sessionid=0x14974a850ae007c
[20141103 16:39:05-INFO][ZooKeeper.java:684][RMI TCP Connection(7)-192.168.10.108]-- Session: 0x14974a850ae007c closed
[20141103 16:39:05-INFO][ClientCnxn.java:509][RMI TCP Connection(7)-192.168.10.108-EventThread]-- EventThread shut down
[20141103 16:39:06-INFO][ZooKeeper.java:438][RMI TCP Connection(7)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x7047125, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:06-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(7)-192.168.10.108]-- Process identifier=hconnection-0x7047125 connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:06-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:06-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:06-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0081, negotiated timeout = 90000
[20141103 16:39:06-INFO][HConnectionManager.java:1798][RMI TCP Connection(7)-192.168.10.108]-- Closing zookeeper sessionid=0x14974a850ae0081
[20141103 16:39:06-INFO][ZooKeeper.java:684][RMI TCP Connection(7)-192.168.10.108]-- Session: 0x14974a850ae0081 closed
[20141103 16:39:06-INFO][ClientCnxn.java:509][RMI TCP Connection(7)-192.168.10.108-EventThread]-- EventThread shut down
[20141103 16:39:54-INFO][ZooKeeper.java:438][DefaultQuartzScheduler_Worker-1]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x307aa898, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:54-INFO][RecoverableZooKeeper.java:120][DefaultQuartzScheduler_Worker-1]-- Process identifier=hconnection-0x307aa898 connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:54-INFO][ClientCnxn.java:966][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:54-INFO][ClientCnxn.java:849][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:54-INFO][ClientCnxn.java:1207][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0082, negotiated timeout = 90000
[20141103 16:39:54-INFO][ZooKeeper.java:438][DefaultQuartzScheduler_Worker-1]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x65820750, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:54-INFO][RecoverableZooKeeper.java:120][DefaultQuartzScheduler_Worker-1]-- Process identifier=hconnection-0x65820750 connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:54-INFO][ClientCnxn.java:966][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:54-INFO][ClientCnxn.java:849][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:54-INFO][ClientCnxn.java:1207][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0083, negotiated timeout = 90000
[20141103 16:39:54-INFO][HConnectionManager.java:1798][DefaultQuartzScheduler_Worker-1]-- Closing zookeeper sessionid=0x14974a850ae0083
[20141103 16:39:54-INFO][ZooKeeper.java:684][DefaultQuartzScheduler_Worker-1]-- Session: 0x14974a850ae0083 closed
[20141103 16:39:54-INFO][ClientCnxn.java:509][DefaultQuartzScheduler_Worker-1-EventThread]-- EventThread shut down
[20141103 16:39:54-INFO][ZooKeeper.java:438][DefaultQuartzScheduler_Worker-1]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x45aeba2, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:54-INFO][RecoverableZooKeeper.java:120][DefaultQuartzScheduler_Worker-1]-- Process identifier=hconnection-0x45aeba2 connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:54-INFO][ClientCnxn.java:966][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:54-INFO][ClientCnxn.java:849][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:54-INFO][ClientCnxn.java:1207][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0084, negotiated timeout = 90000
[20141103 16:39:54-INFO][HConnectionManager.java:1798][DefaultQuartzScheduler_Worker-1]-- Closing zookeeper sessionid=0x14974a850ae0084
[20141103 16:39:54-INFO][ZooKeeper.java:684][DefaultQuartzScheduler_Worker-1]-- Session: 0x14974a850ae0084 closed
[20141103 16:39:54-INFO][ClientCnxn.java:509][DefaultQuartzScheduler_Worker-1-EventThread]-- EventThread shut down
[20141103 16:39:54-INFO][HConnectionManager.java:1798][DefaultQuartzScheduler_Worker-1]-- Closing zookeeper sessionid=0x14974a850ae0082
[20141103 16:39:54-INFO][ZooKeeper.java:684][DefaultQuartzScheduler_Worker-1]-- Session: 0x14974a850ae0082 closed
[20141103 16:39:54-INFO][ClientCnxn.java:509][DefaultQuartzScheduler_Worker-1-EventThread]-- EventThread shut down
[20141103 16:39:54-INFO][ZooKeeper.java:438][DefaultQuartzScheduler_Worker-1]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x3b1e0bba, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:54-INFO][RecoverableZooKeeper.java:120][DefaultQuartzScheduler_Worker-1]-- Process identifier=hconnection-0x3b1e0bba connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:54-INFO][ClientCnxn.java:966][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:54-INFO][ClientCnxn.java:849][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:54-INFO][ClientCnxn.java:1207][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0085, negotiated timeout = 90000
[20141103 16:39:54-INFO][HConnectionManager.java:1798][DefaultQuartzScheduler_Worker-1]-- Closing zookeeper sessionid=0x14974a850ae0085
[20141103 16:39:54-INFO][ClientCnxn.java:509][DefaultQuartzScheduler_Worker-1-EventThread]-- EventThread shut down
[20141103 16:39:54-INFO][ZooKeeper.java:684][DefaultQuartzScheduler_Worker-1]-- Session: 0x14974a850ae0085 closed
[20141103 16:39:54-INFO][DataFetcherDispenser.java:160][DefaultQuartzScheduler_Worker-1]-- Use class com.missionsky.scp.dataadapter.datafetcher.JSONDataFetcher to fetching data of the datasource educationStandard
[20141103 16:39:54-INFO][DataFetcherDispenser.java:165][DefaultQuartzScheduler_Worker-1]-- Create a timer task thread for datasource educationStandard in threadpool.
[20141103 16:39:54-INFO][ZooKeeper.java:438][DefaultQuartzScheduler_Worker-1]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x6ed4c62b, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:54-INFO][RecoverableZooKeeper.java:120][DefaultQuartzScheduler_Worker-1]-- Process identifier=hconnection-0x6ed4c62b connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:54-INFO][ClientCnxn.java:966][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:54-INFO][ClientCnxn.java:849][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:54-INFO][ClientCnxn.java:1207][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0086, negotiated timeout = 90000
[20141103 16:39:54-INFO][ZooKeeper.java:438][DefaultQuartzScheduler_Worker-1]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x2756a312, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:54-INFO][RecoverableZooKeeper.java:120][DefaultQuartzScheduler_Worker-1]-- Process identifier=hconnection-0x2756a312 connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:54-INFO][ClientCnxn.java:966][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:54-INFO][ClientCnxn.java:849][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:54-INFO][ClientCnxn.java:1207][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0087, negotiated timeout = 90000
[20141103 16:39:54-INFO][HConnectionManager.java:1798][DefaultQuartzScheduler_Worker-1]-- Closing zookeeper sessionid=0x14974a850ae0087
[20141103 16:39:54-INFO][ZooKeeper.java:684][DefaultQuartzScheduler_Worker-1]-- Session: 0x14974a850ae0087 closed
[20141103 16:39:54-INFO][ClientCnxn.java:509][DefaultQuartzScheduler_Worker-1-EventThread]-- EventThread shut down
[20141103 16:39:54-INFO][ZooKeeper.java:438][DefaultQuartzScheduler_Worker-1]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x2b79174c, quorum=master:2181, baseZNode=/hbase
[20141103 16:39:54-INFO][RecoverableZooKeeper.java:120][DefaultQuartzScheduler_Worker-1]-- Process identifier=hconnection-0x2b79174c connecting to ZooKeeper ensemble=master:2181
[20141103 16:39:54-INFO][ClientCnxn.java:966][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:39:54-INFO][ClientCnxn.java:849][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:39:54-INFO][ClientCnxn.java:1207][DefaultQuartzScheduler_Worker-1-SendThread(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0088, negotiated timeout = 90000
[20141103 16:39:54-INFO][HConnectionManager.java:1798][DefaultQuartzScheduler_Worker-1]-- Closing zookeeper sessionid=0x14974a850ae0088
[20141103 16:39:54-INFO][ZooKeeper.java:684][DefaultQuartzScheduler_Worker-1]-- Session: 0x14974a850ae0088 closed
[20141103 16:39:54-INFO][ClientCnxn.java:509][DefaultQuartzScheduler_Worker-1-EventThread]-- EventThread shut down
[20141103 16:39:54-INFO][HConnectionManager.java:1798][DefaultQuartzScheduler_Worker-1]-- Closing zookeeper sessionid=0x14974a850ae0086
[20141103 16:39:54-INFO][ZooKeeper.java:684][DefaultQuartzScheduler_Worker-1]-- Session: 0x14974a850ae0086 closed
[20141103 16:39:54-INFO][ClientCnxn.java:509][DefaultQuartzScheduler_Worker-1-EventThread]-- EventThread shut down
[20141103 16:40:00-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:00-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:00-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:00-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:00-INFO][DataFilterApi.java:110][pool-4-thread-1]-- educationStandard directory created.
[20141103 16:40:00-INFO][DataFilterApi.java:120][pool-4-thread-1]-- create file fire_1415004000497 and write data
[20141103 16:40:01-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:01-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:01-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:01-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:01-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:02-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:05-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:05-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:05-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:05-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:05-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:05-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:06-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:06-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:06-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:06-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:06-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:06-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:07-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:07-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:07-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:07-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:08-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:08-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:09-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:09-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:09-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:09-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:09-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:09-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:10-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:10-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:10-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:10-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:10-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:10-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:12-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:12-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:12-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:12-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:12-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:12-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:13-INFO][ZooKeeper.java:438][RMI TCP Connection(8)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x2a76535b, quorum=master:2181, baseZNode=/hbase
[20141103 16:40:13-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(8)-192.168.10.108]-- Process identifier=hconnection-0x2a76535b connecting to ZooKeeper ensemble=master:2181
[20141103 16:40:13-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:40:13-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:40:13-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae008b, negotiated timeout = 90000
[20141103 16:40:13-INFO][HConnectionManager.java:1798][RMI TCP Connection(8)-192.168.10.108]-- Closing zookeeper sessionid=0x14974a850ae008b
[20141103 16:40:13-INFO][ZooKeeper.java:684][RMI TCP Connection(8)-192.168.10.108]-- Session: 0x14974a850ae008b closed
[20141103 16:40:13-INFO][ClientCnxn.java:509][RMI TCP Connection(8)-192.168.10.108-EventThread]-- EventThread shut down
[20141103 16:40:14-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:14-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:14-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:14-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:14-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:14-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:15-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:15-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:15-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:15-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:15-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:16-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:17-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:17-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:17-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:17-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:17-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:17-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:18-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:18-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:18-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:18-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:18-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:18-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:19-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:19-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:19-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:19-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:19-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:19-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:21-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:21-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:21-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:21-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:21-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:21-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:22-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:22-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:22-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:22-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:22-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:22-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:23-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:23-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:23-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:23-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:23-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:23-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:24-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:24-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:24-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:24-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:24-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:24-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:26-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:26-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:26-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:26-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:26-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:26-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:27-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:27-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:27-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:27-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:27-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:27-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:28-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:28-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:28-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:28-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:28-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:29-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:30-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:30-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:30-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:30-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:30-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:30-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:31-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:31-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:31-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:31-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:31-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:31-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:32-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:32-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:32-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:32-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:32-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:32-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:34-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:34-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:34-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:34-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:34-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:34-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:35-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:35-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:35-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:35-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:35-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:35-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:36-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:36-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:36-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:36-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:36-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:37-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:37-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:37-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:37-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:37-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:37-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:37-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:38-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:38-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:38-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:38-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:38-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:38-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:40-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:40-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:40-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:40-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:40-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:40-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:41-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:41-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:41-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:41-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:41-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:41-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:42-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:42-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:42-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:42-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:43-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:43-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:45-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:45-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:45-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:45-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:45-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:45-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:46-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:46-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:46-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:46-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:46-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:47-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:47-INFO][ZooKeeper.java:438][RMI TCP Connection(9)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x7f2d900, quorum=master:2181, baseZNode=/hbase
[20141103 16:40:47-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(9)-192.168.10.108]-- Process identifier=hconnection-0x7f2d900 connecting to ZooKeeper ensemble=master:2181
[20141103 16:40:47-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:40:47-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:40:47-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae008e, negotiated timeout = 90000
[20141103 16:40:47-INFO][HConnectionManager.java:1798][RMI TCP Connection(9)-192.168.10.108]-- Closing zookeeper sessionid=0x14974a850ae008e
[20141103 16:40:47-INFO][ZooKeeper.java:684][RMI TCP Connection(9)-192.168.10.108]-- Session: 0x14974a850ae008e closed
[20141103 16:40:47-INFO][ClientCnxn.java:509][RMI TCP Connection(9)-192.168.10.108-EventThread]-- EventThread shut down
[20141103 16:40:48-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:48-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:48-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:48-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:48-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:48-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:49-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:49-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:49-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:49-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:49-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:49-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:50-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:50-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:50-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:50-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:50-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:51-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:52-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:52-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:52-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:52-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:52-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:52-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:53-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:53-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:53-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:53-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:53-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:53-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:54-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:54-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:54-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:54-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:54-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:55-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:56-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:56-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:56-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:56-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:56-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:56-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:57-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:57-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:57-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:57-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:57-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:57-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:40:58-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:40:58-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:40:58-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:40:58-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:40:58-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:40:58-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:01-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:01-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:01-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:01-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:01-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:01-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:02-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:02-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:02-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:02-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:02-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:03-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:04-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:04-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:04-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:04-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:04-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:04-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:05-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:05-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:05-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:05-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:05-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:05-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:07-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:07-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:07-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:07-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:07-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:07-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:09-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:09-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:09-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:09-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:09-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:09-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:16-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:16-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:16-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:16-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:16-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:16-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:20-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:20-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:20-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:20-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:20-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:20-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:23-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:23-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:23-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:23-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:23-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:23-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:25-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:25-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:25-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:25-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:25-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:25-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:26-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:26-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:26-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:26-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:26-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:26-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:28-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:28-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:28-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:28-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:28-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:28-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:30-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:30-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:30-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:30-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:30-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:30-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:31-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:31-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:31-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:31-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:31-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:31-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:33-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:33-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:33-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:33-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:33-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:33-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:34-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:34-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:34-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:34-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:35-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:35-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:36-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:36-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:36-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:36-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:36-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:36-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:37-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:37-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:37-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:37-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:37-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:37-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:38-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:38-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:38-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:38-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:39-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:39-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:40-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:40-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:40-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:40-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:40-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:40-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:43-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:43-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:43-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:43-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:43-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:43-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:44-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:44-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:44-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:44-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:44-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:45-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:46-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:46-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:46-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:46-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:46-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:46-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:47-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:47-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:47-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:47-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:47-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:47-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:49-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:49-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:49-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:49-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:49-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:49-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:50-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:50-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:50-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:50-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:50-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:51-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:52-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:52-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:52-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:52-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:52-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:52-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:54-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:54-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:54-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:54-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:54-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:54-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:55-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:55-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:55-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:55-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:55-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:55-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:57-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:57-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:57-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:57-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:57-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:57-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:58-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:58-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:58-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:58-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:41:58-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:41:58-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:41:59-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:41:59-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:41:59-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:41:59-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:00-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:00-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:01-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:01-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:01-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:01-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:01-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:01-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:02-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:02-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:02-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:02-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:02-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:02-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:04-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:04-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:04-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:04-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:04-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:04-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:05-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:05-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:05-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:05-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:06-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:06-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:07-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:07-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:07-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:07-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:07-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:07-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:09-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:09-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:09-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:09-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:09-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:09-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:10-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:10-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:10-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:10-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:10-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:11-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:12-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:12-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:12-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:12-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:12-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:12-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:13-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:13-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:13-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:13-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:13-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:14-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:15-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:15-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:15-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:15-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:15-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:15-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:16-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:16-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:16-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:16-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:16-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:17-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:18-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:18-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:18-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:18-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:18-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:18-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:20-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:20-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:20-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:20-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:20-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:20-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:21-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:21-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:21-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:21-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:21-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:22-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:23-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:23-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:23-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:23-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:23-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:23-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:24-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:24-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:24-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:24-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:24-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:24-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:25-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:25-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:25-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:25-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:25-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:25-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:27-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:27-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:27-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:27-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:27-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:27-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:28-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:28-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:28-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:28-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:28-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:28-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:30-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:30-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:30-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:30-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:30-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:30-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:31-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:31-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:31-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:31-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:31-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:31-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:33-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:33-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:33-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:33-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:33-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:34-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:35-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:35-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:35-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:35-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:35-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:35-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:36-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:36-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:36-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:36-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:36-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:36-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:38-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:38-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:38-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:38-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:38-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:38-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:39-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:39-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:39-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:39-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:39-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:39-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:40-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:40-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:40-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:40-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:40-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:41-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:42-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:42-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:42-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:42-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:42-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:42-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:55-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:55-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:55-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:55-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:55-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:55-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:57-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:57-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:57-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:57-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:57-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:57-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:42:59-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:42:59-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:42:59-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:42:59-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:42:59-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:42:59-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:06-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:06-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:06-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:06-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:06-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:06-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:08-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:08-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:08-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:08-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:08-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:08-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:11-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:11-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:11-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:11-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:11-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:11-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:13-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:13-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:13-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:13-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:13-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:13-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:14-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:14-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:14-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:14-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:14-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:14-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:23-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:23-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:23-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:23-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:23-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:23-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:25-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:25-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:25-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:25-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:25-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:25-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:26-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:26-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:26-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:26-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:26-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:27-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:28-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:28-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:28-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:28-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:28-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:29-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:35-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:35-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:35-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:35-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:35-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:36-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:43:51-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:43:51-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:43:51-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:43:51-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:43:51-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:43:51-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:00-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:00-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:00-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:00-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:00-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:00-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:01-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:01-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:01-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:01-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:01-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:01-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:03-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:03-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:03-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:03-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:03-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:03-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:04-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:04-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:04-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:04-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:04-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:04-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:05-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:05-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:05-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:05-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:05-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:05-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:06-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:06-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:06-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:06-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:06-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:07-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:08-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:08-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:08-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:08-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:08-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:08-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:09-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:09-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:09-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:09-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:09-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:09-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:10-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:10-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:10-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:10-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:10-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:10-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:13-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:13-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:13-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:13-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:13-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:13-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:14-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:14-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:14-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:14-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:14-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:14-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:15-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:15-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:15-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:15-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:15-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:15-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:18-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:18-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:18-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:18-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:18-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:18-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:19-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:19-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:19-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:19-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:19-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:19-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:21-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:21-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:21-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:21-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:21-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:21-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:22-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:22-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:22-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:22-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:22-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:22-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:23-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:23-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:23-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:23-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:23-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:23-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:25-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:25-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:25-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:25-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:25-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:25-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:26-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:26-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:26-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:26-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:26-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:26-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:28-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:28-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:28-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:28-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:28-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:28-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:29-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:29-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:29-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:29-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:29-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:29-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:30-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:30-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:30-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:30-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:30-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:30-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:32-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:32-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:32-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:32-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:32-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:32-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:34-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:34-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:34-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:34-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:34-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:34-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:36-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:36-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:36-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:36-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:36-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:36-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:37-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:37-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:37-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:37-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:37-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:37-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:38-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:38-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:38-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:38-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:38-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:39-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:40-INFO][ExcuteFecthThread.java:109][pool-4-thread-1]-- Save data to hdfs.
[20141103 16:44:40-INFO][DataFilterApi.java:45][pool-4-thread-1]-- instanceof object types:Map or List,recommend to use List
[20141103 16:44:40-INFO][DataFilterApi.java:86][pool-4-thread-1]-- transfrom data to byte[]
[20141103 16:44:40-INFO][DataFilterApi.java:88][pool-4-thread-1]-- get file name from xml configuration
[20141103 16:44:40-INFO][DataFilterApi.java:113][pool-4-thread-1]-- educationStandard directory exist.
[20141103 16:44:40-INFO][DataFilterApi.java:126][pool-4-thread-1]-- append data to exist file /Source/educationStandard/fire_1415004000497
[20141103 16:44:40-INFO][ZooKeeper.java:438][pool-4-thread-1]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x5b8cba01, quorum=master:2181, baseZNode=/hbase
[20141103 16:44:40-INFO][RecoverableZooKeeper.java:120][pool-4-thread-1]-- Process identifier=hconnection-0x5b8cba01 connecting to ZooKeeper ensemble=master:2181
[20141103 16:44:40-INFO][ClientCnxn.java:966][pool-4-thread-1-SendThread(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:44:40-INFO][ClientCnxn.java:849][pool-4-thread-1-SendThread(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:44:40-INFO][ClientCnxn.java:1207][pool-4-thread-1-SendThread(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae008f, negotiated timeout = 90000
[20141103 16:44:40-INFO][ZooKeeper.java:438][pool-4-thread-1]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x6493d8f, quorum=master:2181, baseZNode=/hbase
[20141103 16:44:40-INFO][RecoverableZooKeeper.java:120][pool-4-thread-1]-- Process identifier=hconnection-0x6493d8f connecting to ZooKeeper ensemble=master:2181
[20141103 16:44:40-INFO][ClientCnxn.java:966][pool-4-thread-1-SendThread(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:44:40-INFO][ClientCnxn.java:849][pool-4-thread-1-SendThread(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:44:40-INFO][ClientCnxn.java:1207][pool-4-thread-1-SendThread(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0090, negotiated timeout = 90000
[20141103 16:44:40-INFO][HConnectionManager.java:1798][pool-4-thread-1]-- Closing zookeeper sessionid=0x14974a850ae0090
[20141103 16:44:40-INFO][ZooKeeper.java:684][pool-4-thread-1]-- Session: 0x14974a850ae0090 closed
[20141103 16:44:40-INFO][ClientCnxn.java:509][pool-4-thread-1-EventThread]-- EventThread shut down
[20141103 16:44:40-INFO][ZooKeeper.java:438][pool-4-thread-1]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0xc9cd85d, quorum=master:2181, baseZNode=/hbase
[20141103 16:44:40-INFO][RecoverableZooKeeper.java:120][pool-4-thread-1]-- Process identifier=hconnection-0xc9cd85d connecting to ZooKeeper ensemble=master:2181
[20141103 16:44:40-INFO][ClientCnxn.java:966][pool-4-thread-1-SendThread(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:44:40-INFO][ClientCnxn.java:849][pool-4-thread-1-SendThread(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:44:40-INFO][ClientCnxn.java:1207][pool-4-thread-1-SendThread(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0091, negotiated timeout = 90000
[20141103 16:44:40-INFO][HConnectionManager.java:1798][pool-4-thread-1]-- Closing zookeeper sessionid=0x14974a850ae0091
[20141103 16:44:40-INFO][ZooKeeper.java:684][pool-4-thread-1]-- Session: 0x14974a850ae0091 closed
[20141103 16:44:40-INFO][ClientCnxn.java:509][pool-4-thread-1-EventThread]-- EventThread shut down
[20141103 16:44:40-INFO][HConnectionManager.java:1798][pool-4-thread-1]-- Closing zookeeper sessionid=0x14974a850ae008f
[20141103 16:44:40-INFO][ZooKeeper.java:684][pool-4-thread-1]-- Session: 0x14974a850ae008f closed
[20141103 16:44:40-INFO][ClientCnxn.java:509][pool-4-thread-1-EventThread]-- EventThread shut down
[20141103 16:45:21-INFO][ZooKeeper.java:438][RMI TCP Connection(12)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x5074fb60, quorum=master:2181, baseZNode=/hbase
[20141103 16:45:21-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(12)-192.168.10.108]-- Process identifier=hconnection-0x5074fb60 connecting to ZooKeeper ensemble=master:2181
[20141103 16:45:21-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 16:45:21-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 16:45:21-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae0094, negotiated timeout = 90000
[20141103 16:45:21-INFO][HConnectionManager.java:1798][RMI TCP Connection(12)-192.168.10.108]-- Closing zookeeper sessionid=0x14974a850ae0094
[20141103 16:45:21-INFO][ZooKeeper.java:684][RMI TCP Connection(12)-192.168.10.108]-- Session: 0x14974a850ae0094 closed
[20141103 16:45:21-INFO][ClientCnxn.java:509][RMI TCP Connection(12)-192.168.10.108-EventThread]-- EventThread shut down
[20141103 17:33:50-WARN][NativeCodeLoader.java:62][RMI TCP Connection(5)-192.168.10.108]-- Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:host.name=USER-20140101YF
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.version=1.7.0_45
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.vendor=Oracle Corporation
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.home=C:\Program Files\Java\jre7
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.class.path=E:\dataresouce\SCP\scp\scp_data_adapter\target\classes;C:\Users\Administrator\.m2\repository\org\springframework\spring-context\3.2.3.RELEASE\spring-context-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-aop\3.2.3.RELEASE\spring-aop-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-beans\3.2.3.RELEASE\spring-beans-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-core\3.2.3.RELEASE\spring-core-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-expression\3.2.3.RELEASE\spring-expression-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-client\2.5.0\hadoop-client-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-common\2.5.0\hadoop-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\Administrator\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\Administrator\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\Administrator\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\Administrator\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\Administrator\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\Administrator\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.5.0\hadoop-mapreduce-client-app-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.5.0\hadoop-mapreduce-client-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.5.0\hadoop-yarn-client-2.5.0.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.5.0\hadoop-yarn-server-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.5.0\hadoop-mapreduce-client-shuffle-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.0\hadoop-yarn-api-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.0\hadoop-mapreduce-client-core-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.0\hadoop-yarn-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\Administrator\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\Administrator\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.5.0\hadoop-mapreduce-client-jobclient-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.0\hadoop-annotations-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.5.0\hadoop-hdfs-2.5.0.jar;C:\Users\Administrator\.m2\repository\com\google\guava\guava\11.0.2\guava-11.0.2.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\Administrator\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\Administrator\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\Administrator\.m2\repository\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;C:\Users\Administrator\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\Administrator\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\Administrator\.m2\repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;C:\Users\Administrator\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\Administrator\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\Administrator\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\Administrator\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\Administrator\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\Administrator\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\Administrator\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\Administrator\.m2\repository\org\springframework\data\spring-data-hadoop\1.0.1.RELEASE\spring-data-hadoop-1.0.1.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-context-support\3.0.7.RELEASE\spring-context-support-3.0.7.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-streaming\1.2.1\hadoop-streaming-1.2.1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-tools\1.2.1\hadoop-tools-1.2.1.jar;C:\Users\Administrator\.m2\repository\dom4j\dom4j\1.6.1\dom4j-1.6.1.jar;C:\Users\Administrator\.m2\repository\xml-apis\xml-apis\1.0.b2\xml-apis-1.0.b2.jar;C:\Users\Administrator\.m2\repository\org\quartz-scheduler\quartz\2.2.1\quartz-2.2.1.jar;C:\Users\Administrator\.m2\repository\c3p0\c3p0\0.9.1.1\c3p0-0.9.1.1.jar;C:\Users\Administrator\.m2\repository\org\quartz-scheduler\quartz-jobs\2.2.1\quartz-jobs-2.2.1.jar;C:\Users\Administrator\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-api\1.7.5\slf4j-api-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\jcl-over-slf4j\1.7.5\jcl-over-slf4j-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-log4j12\1.7.5\slf4j-log4j12-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-nop\1.7.5\slf4j-nop-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-client\0.96.2-hadoop2\hbase-client-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-common\0.96.2-hadoop2\hbase-common-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-protocol\0.96.2-hadoop2\hbase-protocol-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\zookeeper\zookeeper\3.4.5\zookeeper-3.4.5.jar;C:\Users\Administrator\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\Administrator\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-core\1.2.1\hadoop-core-1.2.1.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-json\1.8\jersey-json-1.8.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\Administrator\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\Administrator\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.7.1\jackson-jaxrs-1.7.1.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-xc\1.7.1\jackson-xc-1.7.1.jar;C:\Users\Administrator\.m2\repository\commons-httpclient\commons-httpclient\3.0.1\commons-httpclient-3.0.1.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\Administrator\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\Administrator\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\Administrator\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\Administrator\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\Administrator\.m2\repository\commons-net\commons-net\1.4.1\commons-net-1.4.1.jar;C:\Users\Administrator\.m2\repository\tomcat\jasper-compiler\5.5.12\jasper-compiler-5.5.12.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\Administrator\.m2\repository\ant\ant\1.6.5\ant-1.6.5.jar;C:\Users\Administrator\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\Administrator\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\Administrator\.m2\repository\hsqldb\hsqldb\1.8.0.10\hsqldb-1.8.0.10.jar;C:\Users\Administrator\.m2\repository\oro\oro\2.0.8\oro-2.0.8.jar;C:\Users\Administrator\.m2\repository\org\eclipse\jdt\core\3.1.1\core-3.1.1.jar
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.library.path=C:\Program Files\Java\jre7\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;%CATALINA_HOME%\bin;\System32\WindowsPowerShell\v1.0\ \C:\Program Files\TortoiseGit\bin;D:\apache-maven-3.0.5\bin;%HADOOP_HOME%\bin;;.
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.compiler=<NA>
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:os.name=Windows 7
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:os.arch=amd64
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:os.version=6.1
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:user.name=Administrator
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:user.home=C:\Users\Administrator
[20141103 17:33:50-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:user.dir=E:\dataresouce\SCP\scp\scp_data_adapter
[20141103 17:33:50-INFO][ZooKeeper.java:438][RMI TCP Connection(5)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x21129634, quorum=master:2181, baseZNode=/hbase
[20141103 17:33:50-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(5)-192.168.10.108]-- Process identifier=hconnection-0x21129634 connecting to ZooKeeper ensemble=master:2181
[20141103 17:33:50-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141103 17:33:50-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141103 17:33:50-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x14974a850ae00e0, negotiated timeout = 90000
[20141103 17:33:51-INFO][HConnectionManager.java:1798][RMI TCP Connection(5)-192.168.10.108]-- Closing zookeeper sessionid=0x14974a850ae00e0
[20141103 17:33:51-INFO][ZooKeeper.java:684][RMI TCP Connection(5)-192.168.10.108]-- Session: 0x14974a850ae00e0 closed
[20141103 17:33:51-INFO][ClientCnxn.java:509][RMI TCP Connection(5)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:45:10-WARN][NativeCodeLoader.java:62][RMI TCP Connection(5)-192.168.10.108]-- Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:host.name=USER-20140101YF
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.version=1.7.0_45
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.vendor=Oracle Corporation
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.home=C:\Program Files\Java\jre7
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.class.path=E:\dataresouce\SCP\scp\scp_data_adapter\target\classes;C:\Users\Administrator\.m2\repository\org\springframework\spring-context\3.2.3.RELEASE\spring-context-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-aop\3.2.3.RELEASE\spring-aop-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-beans\3.2.3.RELEASE\spring-beans-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-core\3.2.3.RELEASE\spring-core-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-expression\3.2.3.RELEASE\spring-expression-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-client\2.5.0\hadoop-client-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-common\2.5.0\hadoop-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\Administrator\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\Administrator\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\Administrator\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\Administrator\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\Administrator\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\Administrator\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.5.0\hadoop-mapreduce-client-app-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.5.0\hadoop-mapreduce-client-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.5.0\hadoop-yarn-client-2.5.0.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.5.0\hadoop-yarn-server-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.5.0\hadoop-mapreduce-client-shuffle-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.0\hadoop-yarn-api-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.0\hadoop-mapreduce-client-core-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.0\hadoop-yarn-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\Administrator\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\Administrator\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.5.0\hadoop-mapreduce-client-jobclient-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.0\hadoop-annotations-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.5.0\hadoop-hdfs-2.5.0.jar;C:\Users\Administrator\.m2\repository\com\google\guava\guava\11.0.2\guava-11.0.2.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\Administrator\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\Administrator\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\Administrator\.m2\repository\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;C:\Users\Administrator\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\Administrator\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\Administrator\.m2\repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;C:\Users\Administrator\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\Administrator\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\Administrator\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\Administrator\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\Administrator\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\Administrator\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\Administrator\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\Administrator\.m2\repository\org\springframework\data\spring-data-hadoop\1.0.1.RELEASE\spring-data-hadoop-1.0.1.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-context-support\3.0.7.RELEASE\spring-context-support-3.0.7.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-streaming\1.2.1\hadoop-streaming-1.2.1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-tools\1.2.1\hadoop-tools-1.2.1.jar;C:\Users\Administrator\.m2\repository\dom4j\dom4j\1.6.1\dom4j-1.6.1.jar;C:\Users\Administrator\.m2\repository\xml-apis\xml-apis\1.0.b2\xml-apis-1.0.b2.jar;C:\Users\Administrator\.m2\repository\org\quartz-scheduler\quartz\2.2.1\quartz-2.2.1.jar;C:\Users\Administrator\.m2\repository\c3p0\c3p0\0.9.1.1\c3p0-0.9.1.1.jar;C:\Users\Administrator\.m2\repository\org\quartz-scheduler\quartz-jobs\2.2.1\quartz-jobs-2.2.1.jar;C:\Users\Administrator\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-api\1.7.5\slf4j-api-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\jcl-over-slf4j\1.7.5\jcl-over-slf4j-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-log4j12\1.7.5\slf4j-log4j12-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-nop\1.7.5\slf4j-nop-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-client\0.96.2-hadoop2\hbase-client-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-common\0.96.2-hadoop2\hbase-common-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-protocol\0.96.2-hadoop2\hbase-protocol-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\zookeeper\zookeeper\3.4.5\zookeeper-3.4.5.jar;C:\Users\Administrator\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\Administrator\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-core\1.2.1\hadoop-core-1.2.1.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-json\1.8\jersey-json-1.8.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\Administrator\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\Administrator\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.7.1\jackson-jaxrs-1.7.1.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-xc\1.7.1\jackson-xc-1.7.1.jar;C:\Users\Administrator\.m2\repository\commons-httpclient\commons-httpclient\3.0.1\commons-httpclient-3.0.1.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\Administrator\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\Administrator\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\Administrator\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\Administrator\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\Administrator\.m2\repository\commons-net\commons-net\1.4.1\commons-net-1.4.1.jar;C:\Users\Administrator\.m2\repository\tomcat\jasper-compiler\5.5.12\jasper-compiler-5.5.12.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\Administrator\.m2\repository\ant\ant\1.6.5\ant-1.6.5.jar;C:\Users\Administrator\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\Administrator\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\Administrator\.m2\repository\hsqldb\hsqldb\1.8.0.10\hsqldb-1.8.0.10.jar;C:\Users\Administrator\.m2\repository\oro\oro\2.0.8\oro-2.0.8.jar;C:\Users\Administrator\.m2\repository\org\eclipse\jdt\core\3.1.1\core-3.1.1.jar
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.library.path=C:\Program Files\Java\jre7\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;%CATALINA_HOME%\bin;\System32\WindowsPowerShell\v1.0\ \C:\Program Files\TortoiseGit\bin;D:\apache-maven-3.0.5\bin;%HADOOP_HOME%\bin;;.
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.compiler=<NA>
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:os.name=Windows 7
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:os.arch=amd64
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:os.version=6.1
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:user.name=Administrator
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:user.home=C:\Users\Administrator
[20141104 09:45:10-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:user.dir=E:\dataresouce\SCP\scp\scp_data_adapter
[20141104 09:45:10-INFO][ZooKeeper.java:438][RMI TCP Connection(5)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x35f83a80, quorum=master:2181, baseZNode=/hbase
[20141104 09:45:10-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(5)-192.168.10.108]-- Process identifier=hconnection-0x35f83a80 connecting to ZooKeeper ensemble=master:2181
[20141104 09:45:10-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:45:10-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:45:10-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0009, negotiated timeout = 90000
[20141104 09:45:11-INFO][HConnectionManager.java:1798][RMI TCP Connection(5)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0009
[20141104 09:45:11-INFO][ZooKeeper.java:684][RMI TCP Connection(5)-192.168.10.108]-- Session: 0x1497879276b0009 closed
[20141104 09:45:11-INFO][ClientCnxn.java:509][RMI TCP Connection(5)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:50:07-INFO][ZooKeeper.java:438][RMI TCP Connection(9)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x27ba52a2, quorum=master:2181, baseZNode=/hbase
[20141104 09:50:07-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(9)-192.168.10.108]-- Process identifier=hconnection-0x27ba52a2 connecting to ZooKeeper ensemble=master:2181
[20141104 09:50:07-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:50:07-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:50:07-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b000f, negotiated timeout = 90000
[20141104 09:50:07-INFO][HConnectionManager.java:1798][RMI TCP Connection(9)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b000f
[20141104 09:50:07-INFO][ZooKeeper.java:684][RMI TCP Connection(9)-192.168.10.108]-- Session: 0x1497879276b000f closed
[20141104 09:50:07-INFO][ClientCnxn.java:509][RMI TCP Connection(9)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:51:41-INFO][ZooKeeper.java:438][RMI TCP Connection(10)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0xb1be2e3, quorum=master:2181, baseZNode=/hbase
[20141104 09:51:41-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(10)-192.168.10.108]-- Process identifier=hconnection-0xb1be2e3 connecting to ZooKeeper ensemble=master:2181
[20141104 09:51:41-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:51:41-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:51:41-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0013, negotiated timeout = 90000
[20141104 09:51:41-INFO][HConnectionManager.java:1798][RMI TCP Connection(10)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0013
[20141104 09:51:41-INFO][ZooKeeper.java:684][RMI TCP Connection(10)-192.168.10.108]-- Session: 0x1497879276b0013 closed
[20141104 09:51:41-INFO][ClientCnxn.java:509][RMI TCP Connection(10)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:55:15-INFO][ZooKeeper.java:438][RMI TCP Connection(13)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x19f4e1c7, quorum=master:2181, baseZNode=/hbase
[20141104 09:55:15-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(13)-192.168.10.108]-- Process identifier=hconnection-0x19f4e1c7 connecting to ZooKeeper ensemble=master:2181
[20141104 09:55:15-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:55:15-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:55:15-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0019, negotiated timeout = 90000
[20141104 09:55:15-INFO][HConnectionManager.java:1798][RMI TCP Connection(13)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0019
[20141104 09:55:15-INFO][ZooKeeper.java:684][RMI TCP Connection(13)-192.168.10.108]-- Session: 0x1497879276b0019 closed
[20141104 09:55:15-INFO][ClientCnxn.java:509][RMI TCP Connection(13)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:55:41-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x62122112, quorum=master:2181, baseZNode=/hbase
[20141104 09:55:41-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x62122112 connecting to ZooKeeper ensemble=master:2181
[20141104 09:55:41-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:55:41-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:55:41-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b001f, negotiated timeout = 90000
[20141104 09:55:41-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b001f
[20141104 09:55:41-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b001f closed
[20141104 09:55:41-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:55:41-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x61616da4, quorum=master:2181, baseZNode=/hbase
[20141104 09:55:41-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x61616da4 connecting to ZooKeeper ensemble=master:2181
[20141104 09:55:41-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:55:41-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:55:41-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0020, negotiated timeout = 90000
[20141104 09:55:41-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0020
[20141104 09:55:41-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0020 closed
[20141104 09:55:41-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:55:43-INFO][StdSchedulerFactory.java:1184][RMI TCP Connection(14)-192.168.10.108]-- Using default implementation for ThreadExecutor
[20141104 09:55:43-INFO][SimpleThreadPool.java:268][RMI TCP Connection(14)-192.168.10.108]-- Job execution threads will use class loader of thread: RMI TCP Connection(14)-192.168.10.108
[20141104 09:55:43-INFO][SchedulerSignalerImpl.java:61][RMI TCP Connection(14)-192.168.10.108]-- Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
[20141104 09:55:43-INFO][QuartzScheduler.java:240][RMI TCP Connection(14)-192.168.10.108]-- Quartz Scheduler v.2.2.1 created.
[20141104 09:55:43-INFO][RAMJobStore.java:155][RMI TCP Connection(14)-192.168.10.108]-- RAMJobStore initialized.
[20141104 09:55:43-INFO][QuartzScheduler.java:305][RMI TCP Connection(14)-192.168.10.108]-- Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

[20141104 09:55:43-INFO][StdSchedulerFactory.java:1339][RMI TCP Connection(14)-192.168.10.108]-- Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
[20141104 09:55:43-INFO][StdSchedulerFactory.java:1343][RMI TCP Connection(14)-192.168.10.108]-- Quartz scheduler version: 2.2.1
[20141104 09:55:43-INFO][QuartzScheduler.java:575][RMI TCP Connection(14)-192.168.10.108]-- Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
[20141104 09:55:43-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x7f603546, quorum=master:2181, baseZNode=/hbase
[20141104 09:55:43-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x7f603546 connecting to ZooKeeper ensemble=master:2181
[20141104 09:55:43-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:55:43-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:55:43-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0022, negotiated timeout = 90000
[20141104 09:55:43-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x201df488, quorum=master:2181, baseZNode=/hbase
[20141104 09:55:43-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x201df488 connecting to ZooKeeper ensemble=master:2181
[20141104 09:55:43-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:55:43-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:55:43-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0023, negotiated timeout = 90000
[20141104 09:55:44-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0023
[20141104 09:55:44-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0023 closed
[20141104 09:55:44-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:55:44-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x2e0e3609, quorum=master:2181, baseZNode=/hbase
[20141104 09:55:44-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x2e0e3609 connecting to ZooKeeper ensemble=master:2181
[20141104 09:55:44-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:55:44-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:55:44-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0024, negotiated timeout = 90000
[20141104 09:55:44-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0024
[20141104 09:55:44-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0024 closed
[20141104 09:55:44-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:55:44-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0022
[20141104 09:55:44-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0022 closed
[20141104 09:55:44-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:55:45-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x52a1bab6, quorum=master:2181, baseZNode=/hbase
[20141104 09:55:45-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x52a1bab6 connecting to ZooKeeper ensemble=master:2181
[20141104 09:55:45-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:55:45-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:55:45-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0028, negotiated timeout = 90000
[20141104 09:55:45-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0028
[20141104 09:55:45-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0028 closed
[20141104 09:55:45-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:55:46-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x3b5d5e0d, quorum=master:2181, baseZNode=/hbase
[20141104 09:55:46-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x3b5d5e0d connecting to ZooKeeper ensemble=master:2181
[20141104 09:55:46-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:55:46-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:55:46-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0029, negotiated timeout = 90000
[20141104 09:55:46-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0029
[20141104 09:55:46-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0029 closed
[20141104 09:55:46-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:08-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x6ccda74b, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:08-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x6ccda74b connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:08-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:08-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:08-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0030, negotiated timeout = 90000
[20141104 09:56:08-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0030
[20141104 09:56:08-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0030 closed
[20141104 09:56:08-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:08-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x530db33e, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:08-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x530db33e connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:08-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:08-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:08-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0031, negotiated timeout = 90000
[20141104 09:56:08-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0031
[20141104 09:56:08-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0031 closed
[20141104 09:56:08-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:08-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0xa8cac53, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:08-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0xa8cac53 connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:08-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:08-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:08-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0032, negotiated timeout = 90000
[20141104 09:56:08-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0032
[20141104 09:56:08-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0032 closed
[20141104 09:56:08-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:11-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x797937ab, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:11-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x797937ab connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:11-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:11-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:11-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0034, negotiated timeout = 90000
[20141104 09:56:11-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x50db6129, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:11-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x50db6129 connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:11-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:11-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:11-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0035, negotiated timeout = 90000
[20141104 09:56:11-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0035
[20141104 09:56:11-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0035 closed
[20141104 09:56:11-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:11-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x190802f1, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:11-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x190802f1 connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:11-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:11-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:11-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0036, negotiated timeout = 90000
[20141104 09:56:11-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0036
[20141104 09:56:11-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0036 closed
[20141104 09:56:11-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:11-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0034
[20141104 09:56:11-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0034 closed
[20141104 09:56:11-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:13-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x3a01007a, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:13-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x3a01007a connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:13-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:13-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:13-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b003b, negotiated timeout = 90000
[20141104 09:56:13-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b003b
[20141104 09:56:13-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b003b closed
[20141104 09:56:13-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:13-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x69037c66, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:13-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x69037c66 connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:13-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:13-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:13-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b003c, negotiated timeout = 90000
[20141104 09:56:13-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b003c
[20141104 09:56:13-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b003c closed
[20141104 09:56:13-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:13-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x2b36db45, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:13-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x2b36db45 connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:13-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:13-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:13-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b003d, negotiated timeout = 90000
[20141104 09:56:13-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b003d
[20141104 09:56:13-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b003d closed
[20141104 09:56:13-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:22-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x7c8adf94, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:22-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x7c8adf94 connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:22-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:22-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:22-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0043, negotiated timeout = 90000
[20141104 09:56:22-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0043
[20141104 09:56:22-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0043 closed
[20141104 09:56:22-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:23-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x7a6a4b32, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:23-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x7a6a4b32 connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:23-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:23-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:23-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0044, negotiated timeout = 90000
[20141104 09:56:23-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0044
[20141104 09:56:23-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0044 closed
[20141104 09:56:23-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 09:56:26-INFO][ZooKeeper.java:438][RMI TCP Connection(14)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x7312ad46, quorum=master:2181, baseZNode=/hbase
[20141104 09:56:26-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(14)-192.168.10.108]-- Process identifier=hconnection-0x7312ad46 connecting to ZooKeeper ensemble=master:2181
[20141104 09:56:26-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 09:56:26-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 09:56:26-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b0049, negotiated timeout = 90000
[20141104 09:56:26-INFO][HConnectionManager.java:1798][RMI TCP Connection(14)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b0049
[20141104 09:56:26-INFO][ZooKeeper.java:684][RMI TCP Connection(14)-192.168.10.108]-- Session: 0x1497879276b0049 closed
[20141104 09:56:26-INFO][ClientCnxn.java:509][RMI TCP Connection(14)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 10:01:53-WARN][NativeCodeLoader.java:62][RMI TCP Connection(5)-192.168.10.108]-- Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:host.name=USER-20140101YF
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.version=1.7.0_45
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.vendor=Oracle Corporation
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.home=C:\Program Files\Java\jre7
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.class.path=E:\dataresouce\SCP\scp\scp_data_adapter\target\classes;C:\Users\Administrator\.m2\repository\org\springframework\spring-context\3.2.3.RELEASE\spring-context-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-aop\3.2.3.RELEASE\spring-aop-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\aopalliance\aopalliance\1.0\aopalliance-1.0.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-beans\3.2.3.RELEASE\spring-beans-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-core\3.2.3.RELEASE\spring-core-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-expression\3.2.3.RELEASE\spring-expression-3.2.3.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-client\2.5.0\hadoop-client-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-common\2.5.0\hadoop-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-math3\3.1.1\commons-math3-3.1.1.jar;C:\Users\Administrator\.m2\repository\commons-collections\commons-collections\3.2.1\commons-collections-3.2.1.jar;C:\Users\Administrator\.m2\repository\org\apache\avro\avro\1.7.4\avro-1.7.4.jar;C:\Users\Administrator\.m2\repository\com\thoughtworks\paranamer\paranamer\2.3\paranamer-2.3.jar;C:\Users\Administrator\.m2\repository\org\xerial\snappy\snappy-java\1.0.4.1\snappy-java-1.0.4.1.jar;C:\Users\Administrator\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\Administrator\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.5.0\hadoop-mapreduce-client-app-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.5.0\hadoop-mapreduce-client-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.5.0\hadoop-yarn-client-2.5.0.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-client\1.9\jersey-client-1.9.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.5.0\hadoop-yarn-server-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.5.0\hadoop-mapreduce-client-shuffle-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.5.0\hadoop-yarn-api-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.5.0\hadoop-mapreduce-client-core-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.5.0\hadoop-yarn-common-2.5.0.jar;C:\Users\Administrator\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\Administrator\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\Administrator\.m2\repository\javax\activation\activation\1.1\activation-1.1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.5.0\hadoop-mapreduce-client-jobclient-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-annotations\2.5.0\hadoop-annotations-2.5.0.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.5.0\hadoop-hdfs-2.5.0.jar;C:\Users\Administrator\.m2\repository\com\google\guava\guava\11.0.2\guava-11.0.2.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jetty\6.1.26\jetty-6.1.26.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-core\1.9\jersey-core-1.9.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-server\1.9\jersey-server-1.9.jar;C:\Users\Administrator\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\Administrator\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\Administrator\.m2\repository\commons-codec\commons-codec\1.4\commons-codec-1.4.jar;C:\Users\Administrator\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\Administrator\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\Administrator\.m2\repository\commons-logging\commons-logging\1.1.3\commons-logging-1.1.3.jar;C:\Users\Administrator\.m2\repository\commons-daemon\commons-daemon\1.0.13\commons-daemon-1.0.13.jar;C:\Users\Administrator\.m2\repository\javax\servlet\jsp\jsp-api\2.1\jsp-api-2.1.jar;C:\Users\Administrator\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\Administrator\.m2\repository\javax\servlet\servlet-api\2.5\servlet-api-2.5.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\Administrator\.m2\repository\tomcat\jasper-runtime\5.5.23\jasper-runtime-5.5.23.jar;C:\Users\Administrator\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\Administrator\.m2\repository\io\netty\netty\3.6.2.Final\netty-3.6.2.Final.jar;C:\Users\Administrator\.m2\repository\org\springframework\data\spring-data-hadoop\1.0.1.RELEASE\spring-data-hadoop-1.0.1.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\springframework\spring-context-support\3.0.7.RELEASE\spring-context-support-3.0.7.RELEASE.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-streaming\1.2.1\hadoop-streaming-1.2.1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-tools\1.2.1\hadoop-tools-1.2.1.jar;C:\Users\Administrator\.m2\repository\dom4j\dom4j\1.6.1\dom4j-1.6.1.jar;C:\Users\Administrator\.m2\repository\xml-apis\xml-apis\1.0.b2\xml-apis-1.0.b2.jar;C:\Users\Administrator\.m2\repository\org\quartz-scheduler\quartz\2.2.1\quartz-2.2.1.jar;C:\Users\Administrator\.m2\repository\c3p0\c3p0\0.9.1.1\c3p0-0.9.1.1.jar;C:\Users\Administrator\.m2\repository\org\quartz-scheduler\quartz-jobs\2.2.1\quartz-jobs-2.2.1.jar;C:\Users\Administrator\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-api\1.7.5\slf4j-api-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\jcl-over-slf4j\1.7.5\jcl-over-slf4j-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-log4j12\1.7.5\slf4j-log4j12-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\slf4j\slf4j-nop\1.7.5\slf4j-nop-1.7.5.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-client\0.96.2-hadoop2\hbase-client-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-common\0.96.2-hadoop2\hbase-common-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\hbase\hbase-protocol\0.96.2-hadoop2\hbase-protocol-0.96.2-hadoop2.jar;C:\Users\Administrator\.m2\repository\org\apache\zookeeper\zookeeper\3.4.5\zookeeper-3.4.5.jar;C:\Users\Administrator\.m2\repository\org\cloudera\htrace\htrace-core\2.04\htrace-core-2.04.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-auth\2.2.0\hadoop-auth-2.2.0.jar;C:\Users\Administrator\.m2\repository\com\github\stephenc\findbugs\findbugs-annotations\1.3.9-1\findbugs-annotations-1.3.9-1.jar;C:\Users\Administrator\.m2\repository\org\apache\hadoop\hadoop-core\1.2.1\hadoop-core-1.2.1.jar;C:\Users\Administrator\.m2\repository\com\sun\jersey\jersey-json\1.8\jersey-json-1.8.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jettison\jettison\1.1\jettison-1.1.jar;C:\Users\Administrator\.m2\repository\stax\stax-api\1.0.1\stax-api-1.0.1.jar;C:\Users\Administrator\.m2\repository\com\sun\xml\bind\jaxb-impl\2.2.3-1\jaxb-impl-2.2.3-1.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.7.1\jackson-jaxrs-1.7.1.jar;C:\Users\Administrator\.m2\repository\org\codehaus\jackson\jackson-xc\1.7.1\jackson-xc-1.7.1.jar;C:\Users\Administrator\.m2\repository\commons-httpclient\commons-httpclient\3.0.1\commons-httpclient-3.0.1.jar;C:\Users\Administrator\.m2\repository\org\apache\commons\commons-math\2.1\commons-math-2.1.jar;C:\Users\Administrator\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\Administrator\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\Administrator\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\Administrator\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\Administrator\.m2\repository\commons-net\commons-net\1.4.1\commons-net-1.4.1.jar;C:\Users\Administrator\.m2\repository\tomcat\jasper-compiler\5.5.12\jasper-compiler-5.5.12.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jsp-api-2.1\6.1.14\jsp-api-2.1-6.1.14.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\servlet-api-2.5\6.1.14\servlet-api-2.5-6.1.14.jar;C:\Users\Administrator\.m2\repository\org\mortbay\jetty\jsp-2.1\6.1.14\jsp-2.1-6.1.14.jar;C:\Users\Administrator\.m2\repository\ant\ant\1.6.5\ant-1.6.5.jar;C:\Users\Administrator\.m2\repository\commons-el\commons-el\1.0\commons-el-1.0.jar;C:\Users\Administrator\.m2\repository\net\java\dev\jets3t\jets3t\0.6.1\jets3t-0.6.1.jar;C:\Users\Administrator\.m2\repository\hsqldb\hsqldb\1.8.0.10\hsqldb-1.8.0.10.jar;C:\Users\Administrator\.m2\repository\oro\oro\2.0.8\oro-2.0.8.jar;C:\Users\Administrator\.m2\repository\org\eclipse\jdt\core\3.1.1\core-3.1.1.jar
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.library.path=C:\Program Files\Java\jre7\bin;C:\windows\Sun\Java\bin;C:\windows\system32;C:\windows;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows%JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;%CATALINA_HOME%\bin;\System32\WindowsPowerShell\v1.0\ \C:\Program Files\TortoiseGit\bin;D:\apache-maven-3.0.5\bin;%HADOOP_HOME%\bin;;.
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.io.tmpdir=C:\Users\ADMINI~1\AppData\Local\Temp\
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:java.compiler=<NA>
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:os.name=Windows 7
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:os.arch=amd64
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:os.version=6.1
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:user.name=Administrator
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:user.home=C:\Users\Administrator
[20141104 10:01:53-INFO][Environment.java:100][RMI TCP Connection(5)-192.168.10.108]-- Client environment:user.dir=E:\dataresouce\SCP\scp\scp_data_adapter
[20141104 10:01:53-INFO][ZooKeeper.java:438][RMI TCP Connection(5)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x2e32b816, quorum=master:2181, baseZNode=/hbase
[20141104 10:01:53-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(5)-192.168.10.108]-- Process identifier=hconnection-0x2e32b816 connecting to ZooKeeper ensemble=master:2181
[20141104 10:01:53-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 10:01:53-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 10:01:53-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b00b8, negotiated timeout = 90000
[20141104 10:01:54-INFO][HConnectionManager.java:1798][RMI TCP Connection(5)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b00b8
[20141104 10:01:54-INFO][ZooKeeper.java:684][RMI TCP Connection(5)-192.168.10.108]-- Session: 0x1497879276b00b8 closed
[20141104 10:01:54-INFO][ClientCnxn.java:509][RMI TCP Connection(5)-192.168.10.108-EventThread]-- EventThread shut down
[20141104 10:07:09-INFO][ZooKeeper.java:438][RMI TCP Connection(9)-192.168.10.108]-- Initiating client connection, connectString=master:2181 sessionTimeout=90000 watcher=hconnection-0x950aa31, quorum=master:2181, baseZNode=/hbase
[20141104 10:07:09-INFO][RecoverableZooKeeper.java:120][RMI TCP Connection(9)-192.168.10.108]-- Process identifier=hconnection-0x950aa31 connecting to ZooKeeper ensemble=master:2181
[20141104 10:07:09-INFO][ClientCnxn.java:966][RMI TCP Connection(master:2181)]-- Opening socket connection to server master/192.168.10.115:2181. Will not attempt to authenticate using SASL (unknown error)
[20141104 10:07:09-INFO][ClientCnxn.java:849][RMI TCP Connection(master:2181)]-- Socket connection established to master/192.168.10.115:2181, initiating session
[20141104 10:07:09-INFO][ClientCnxn.java:1207][RMI TCP Connection(master:2181)]-- Session establishment complete on server master/192.168.10.115:2181, sessionid = 0x1497879276b00bd, negotiated timeout = 90000
[20141104 10:07:09-INFO][HConnectionManager.java:1798][RMI TCP Connection(9)-192.168.10.108]-- Closing zookeeper sessionid=0x1497879276b00bd
[20141104 10:07:09-INFO][ZooKeeper.java:684][RMI TCP Connection(9)-192.168.10.108]-- Session: 0x1497879276b00bd closed
[20141104 10:07:09-INFO][ClientCnxn.java:509][RMI TCP Connection(9)-192.168.10.108-EventThread]-- EventThread shut down
